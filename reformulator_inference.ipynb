{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79488b174ccc4d2980d16a679cca9315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_189739f4bff24ba3af39b945b114b6a0",
              "IPY_MODEL_2bd79f3a51e14a9a9c7e7e493ae74c48",
              "IPY_MODEL_d909e611f57b43e8a7f8fd88b7fa44c1"
            ],
            "layout": "IPY_MODEL_c69f6c657c934109aa8a939342e2d22a"
          }
        },
        "189739f4bff24ba3af39b945b114b6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b04540d8114a99838ce87f8f620834",
            "placeholder": "​",
            "style": "IPY_MODEL_25c4418fe18c4b4ea04d43466d13de70",
            "value": "Downloading: 100%"
          }
        },
        "2bd79f3a51e14a9a9c7e7e493ae74c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d84525a84774a11a0a94de27de1d506",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8054b77cecd468db046e63761fe69df",
            "value": 25
          }
        },
        "d909e611f57b43e8a7f8fd88b7fa44c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a120648d5947bdb1bd149311781f57",
            "placeholder": "​",
            "style": "IPY_MODEL_a8415ffeb9504851a98e6daa300b9950",
            "value": " 25.0/25.0 [00:00&lt;00:00, 175B/s]"
          }
        },
        "c69f6c657c934109aa8a939342e2d22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b04540d8114a99838ce87f8f620834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c4418fe18c4b4ea04d43466d13de70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d84525a84774a11a0a94de27de1d506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8054b77cecd468db046e63761fe69df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56a120648d5947bdb1bd149311781f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8415ffeb9504851a98e6daa300b9950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572fdb37566e41a0b80ae4de3e82a18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98f4a1dcc69d4844a9f7f2c195ee83ba",
              "IPY_MODEL_42c138e1fe1646789070a5ed6f1ca15f",
              "IPY_MODEL_6824dae960964163b3e02e588b07ac87"
            ],
            "layout": "IPY_MODEL_8f4656a7e5d04f5f9987dfd111e636c2"
          }
        },
        "98f4a1dcc69d4844a9f7f2c195ee83ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9711a6d855f2483e9cc84272177fd4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_47c7e1c792e84864bf87ef8a6117991c",
            "value": "Downloading: 100%"
          }
        },
        "42c138e1fe1646789070a5ed6f1ca15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8726df5acdb4509ac43c2bbbc1c0fb0",
            "max": 1230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85053c24e2774c7bbad0397d629e1f00",
            "value": 1230
          }
        },
        "6824dae960964163b3e02e588b07ac87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f88056197a49a5a4ffb36cb5e3dbcc",
            "placeholder": "​",
            "style": "IPY_MODEL_f856012c1efd4258b0b5f7a1c845e1b9",
            "value": " 1.23k/1.23k [00:00&lt;00:00, 6.47kB/s]"
          }
        },
        "8f4656a7e5d04f5f9987dfd111e636c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9711a6d855f2483e9cc84272177fd4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c7e1c792e84864bf87ef8a6117991c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8726df5acdb4509ac43c2bbbc1c0fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85053c24e2774c7bbad0397d629e1f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2f88056197a49a5a4ffb36cb5e3dbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f856012c1efd4258b0b5f7a1c845e1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe596ff90c74faebb770a88e3c3d8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a182775d5b345bba335f28698023190",
              "IPY_MODEL_a31366c7e11f41bf9a80651821712813",
              "IPY_MODEL_cc83c3fb50ab435d89171e9aa8f1c040"
            ],
            "layout": "IPY_MODEL_0d0722222d3a48dea4a347f13d390672"
          }
        },
        "6a182775d5b345bba335f28698023190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a491a4428e74a84bad6f4e812f08855",
            "placeholder": "​",
            "style": "IPY_MODEL_9ddbc7e353864fa3a1977aa89597bdf2",
            "value": "Downloading: 100%"
          }
        },
        "a31366c7e11f41bf9a80651821712813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2315d2f8e864f439282cea93f16e360",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0156f0225b4348f389b9960e3d081364",
            "value": 791656
          }
        },
        "cc83c3fb50ab435d89171e9aa8f1c040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f232e01b610b45aeabe7112e6d625996",
            "placeholder": "​",
            "style": "IPY_MODEL_3e12ae1891fa4555b77c89546bc29ad6",
            "value": " 792k/792k [00:00&lt;00:00, 1.55MB/s]"
          }
        },
        "0d0722222d3a48dea4a347f13d390672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a491a4428e74a84bad6f4e812f08855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ddbc7e353864fa3a1977aa89597bdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2315d2f8e864f439282cea93f16e360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0156f0225b4348f389b9960e3d081364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f232e01b610b45aeabe7112e6d625996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e12ae1891fa4555b77c89546bc29ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f083f92b327d480c89271fdef5d31bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f7389504a045e3862fd06946015d8a",
              "IPY_MODEL_4c6885b6f2c046bcb18de2273a6a6d9c",
              "IPY_MODEL_443bebc1c64447a3b38093dd7fad1aa0"
            ],
            "layout": "IPY_MODEL_994cce208d2745c1900d6416c27e0b5f"
          }
        },
        "62f7389504a045e3862fd06946015d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51245153225749819d1940924bfabfdb",
            "placeholder": "​",
            "style": "IPY_MODEL_516720edae8c4de090e887e6b28b74da",
            "value": "Downloading: 100%"
          }
        },
        "4c6885b6f2c046bcb18de2273a6a6d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6410aae9620a4f9c9a2b2f1d5c735314",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d327d681ad047acb51047187a01915e",
            "value": 1786
          }
        },
        "443bebc1c64447a3b38093dd7fad1aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce4bc9df9c2457b9ef5e15936aa05c7",
            "placeholder": "​",
            "style": "IPY_MODEL_562f1a0ef54e44e4b1af390e408c1590",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "994cce208d2745c1900d6416c27e0b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51245153225749819d1940924bfabfdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516720edae8c4de090e887e6b28b74da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6410aae9620a4f9c9a2b2f1d5c735314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d327d681ad047acb51047187a01915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bce4bc9df9c2457b9ef5e15936aa05c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562f1a0ef54e44e4b1af390e408c1590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc55cc7810b94e268fbb76077ddca0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37679f280fd845e593d2c5cdd3452309",
              "IPY_MODEL_ba7b55dd6c514ee8bfd3bbe258e8a093",
              "IPY_MODEL_6fd3c64c0a66404e9dadad1a6300c499"
            ],
            "layout": "IPY_MODEL_2f72de0bdd4d49a7b5cc20e415494c14"
          }
        },
        "37679f280fd845e593d2c5cdd3452309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd18c33670854db2a9fde9d1aeaf5859",
            "placeholder": "​",
            "style": "IPY_MODEL_84d5ce3376e746c48638ef66f1cb7490",
            "value": "Downloading: 100%"
          }
        },
        "ba7b55dd6c514ee8bfd3bbe258e8a093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85b97af3ca8c4273acd3551912a08395",
            "max": 1187795641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4a1e2d0dece4feb9df2e02d4cecff81",
            "value": 1187795641
          }
        },
        "6fd3c64c0a66404e9dadad1a6300c499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13575c25000473ea28b3efe6b397da7",
            "placeholder": "​",
            "style": "IPY_MODEL_efbba048f7fc4bbe8fb3cf061ae3dafc",
            "value": " 1.19G/1.19G [00:43&lt;00:00, 31.0MB/s]"
          }
        },
        "2f72de0bdd4d49a7b5cc20e415494c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd18c33670854db2a9fde9d1aeaf5859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d5ce3376e746c48638ef66f1cb7490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85b97af3ca8c4273acd3551912a08395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a1e2d0dece4feb9df2e02d4cecff81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d13575c25000473ea28b3efe6b397da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efbba048f7fc4bbe8fb3cf061ae3dafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sZX6jIwwgutG"
      },
      "outputs": [],
      "source": [
        "#TODO: Insert train/validation loss plot + EM/F1 scores for original reformulator\n",
        "\n",
        "#TODO: Insert train/validation loss plot + EM/F1 scores for filtered reformulator\n",
        "\n",
        "#TODO: get count of dataset, get count of filtered dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "w3mOCQ-fia2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGt6IVIricLy",
        "outputId": "d01b5be3-7e60-48f4-8d92-0d126b12f0df"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_vali = [1.001426, 0.964072, 0.943505, 0.928900, 0.923954, 0.913895, 0.910533, 0.907546,0.907201]\n",
        "filtered_train = [1.486300, 1.372500, 1.334900, 1.313200, 1.294600, 1.285800, 1.276900, 1.271200, 1.264500]\n",
        "labels = [100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
        "x = [0,1,2,3,4,5,6,7,8]"
      ],
      "metadata": {
        "id": "L90GudZqis59"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(filtered_train)\n",
        "plt.plot(filtered_vali)\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Steps')\n",
        "plt.xticks(x, labels)  # Set label locations.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "saE2WISCjw70",
        "outputId": "c3786119-ac02-41f6-e2ab-fe330231c635"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po_4GRvOmFMo",
        "outputId": "e2631ab1-6fc3-4102-c738-a77e74cdcfbb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_mqr_df = pd.read_csv('drive/MyDrive/t5-data/download/train_mqr_with_category.tsv', sep='\\t')\n",
        "test_mqr_df = pd.read_csv('drive/MyDrive/t5-data/download/test_mqr_with_category.tsv', sep='\\t')\n",
        "\n"
      ],
      "metadata": {
        "id": "6DL9V7SCmKIk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_mqr_df.count())\n",
        "print(test_mqr_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZv3IJwTmQ-h",
        "outputId": "c54483b4-bf3d-4ea0-a252-7fe2c4f0e1f3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ill formed     423494\n",
            "well formed    423494\n",
            "category       423494\n",
            "dtype: int64\n",
            "ill formed     2113\n",
            "well formed    2113\n",
            "category       2113\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(\"Ill formed: \", train_mqr_df['ill formed'][i])\n",
        "  print(\"Well formed: \", train_mqr_df['well formed'][i])"
      ],
      "metadata": {
        "id": "VYKLiktln5IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mqr_df_filtered = pd.read_csv('drive/MyDrive/t5-data/download/mqr_with_category_train_filtered.csv')\n",
        "train_mqr_df_filtered.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYKrgke8mqeP",
        "outputId": "5723e90b-39fe-46e9-fb6e-14e582459b0a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0     96286\n",
              "ill formed     96286\n",
              "well formed    96286\n",
              "category       96286\n",
              "make           96286\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(\"Ill formed: \", train_mqr_df_filtered['ill formed'][i])\n",
        "  print(\"Well formed: \", train_mqr_df_filtered['well formed'][i])"
      ],
      "metadata": {
        "id": "nMHuThpBnAmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollator, T5ForConditionalGeneration, T5TokenizerFast\n",
        "model = T5ForConditionalGeneration.from_pretrained('drive/MyDrive/t5-results/saved/checkpoint-3900')\n",
        "tokenizer = T5TokenizerFast.from_pretrained('t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G26PgRY5rvLB",
        "outputId": "0b92f39c-0252-40a8-8f34-3c1868f4dc8e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "aJF6Mpo9sJE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##inference\n",
        "import json\n",
        "with open('drive/MyDrive/t5-data/download/sample_questions.json','r') as file:\n",
        "  sample_questions = json.load(file)\n",
        "\n",
        "def hf_run_model(input_string, category, **generator_args):\n",
        "  generator_args = {\n",
        "  \"max_length\": 256,\n",
        "  \"num_beams\": 4,\n",
        "  \"length_penalty\": 1.5,\n",
        "  \"no_repeat_ngram_size\": 3,\n",
        "  \"early_stopping\": True,\n",
        "  }\n",
        "  input_string = \"generate question: \" + category + input_string + \" </s>\"\n",
        "  input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
        "  res = model.generate(input_ids.to(device), **generator_args)\n",
        "  output = tokenizer.batch_decode(res, skip_special_tokens=True)\n",
        "  output = [item.split(\"<sep>\") for item in output]\n",
        "  return output\n",
        "\n",
        "\n",
        "for sam in sample_questions:\n",
        "  question, category = sam['question'], sam['category']\n",
        "  pred = hf_run_model(question, category)\n",
        "  sam['predicted_question'] = pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "LhlLT_JGnKlY",
        "outputId": "f20105e3-a59f-4fca-8f2a-788bc4944bcf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-501537a20e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_run_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_question'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-501537a20e12>\u001b[0m in \u001b[0;36mhf_run_model\u001b[0;34m(input_string, category, **generator_args)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0minput_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"generate question: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_string\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" </s>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerator_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<sep>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             )\n\u001b[1;32m   1607\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2800\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 )\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_questions[0:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdsCDADesTzz",
        "outputId": "34d22e49-4f97-4031-9678-20cbe9bc9b5e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'category': 'COMMON BONDS',\n",
              "  'air_date': '1998-09-07',\n",
              "  'question': \"'A game of footsie,<br />a bribe,<br />a drunk person'\",\n",
              "  'value': '$500',\n",
              "  'answer': 'Things that are done under the table',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '3216',\n",
              "  'predicted_question': [['question: What is the difference between a game of footsie,br />a bribe and a drunk person?']]},\n",
              " {'category': 'CONGRESSIONAL MISDEMEANORS',\n",
              "  'air_date': '2005-06-29',\n",
              "  'question': \"'Senator Benjamin Tappan was censured in 1844 for leaking information about the annexation of this to the Union'\",\n",
              "  'value': '$2000',\n",
              "  'answer': 'Texas',\n",
              "  'round': 'Double Jeopardy!',\n",
              "  'show_number': '4808',\n",
              "  'predicted_question': [['question: Why was Benjamin Tappan censured in 1844 for leaking information about the annexation of this to the Union?']]},\n",
              " {'category': 'THE CHAIN GANG',\n",
              "  'air_date': '1998-05-22',\n",
              "  'question': '\\'In any of this chain of theme parks, like the one \"Over Texas\", you might run into Looney Tunes characters\\'',\n",
              "  'value': '$100',\n",
              "  'answer': 'Six Flags',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '3175',\n",
              "  'predicted_question': [['question: How do you run into Looney Tunes characters in any of this chain of theme parks?']]},\n",
              " {'category': '11-LETTER WORDS',\n",
              "  'air_date': '1990-03-26',\n",
              "  'question': \"'A fashion or fad maker'\",\n",
              "  'value': '$400',\n",
              "  'answer': 'Trendsetter',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '1291',\n",
              "  'predicted_question': [[\"question: Is 11-LETTER WORDS'A fashion or fad maker?\"]]},\n",
              " {'category': 'SUPERSTITIONS',\n",
              "  'air_date': '1996-09-02',\n",
              "  'question': \"'Don't ask a fisherman this question; if he answers, it'll stop his streak'\",\n",
              "  'value': '$200',\n",
              "  'answer': '\"Did you catch any?\" (or \"Are they biting?\")',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '2756',\n",
              "  'predicted_question': [[\"question: Why don't I ask a fisherman this question; if he answers, it'll stop his streak?\"]]},\n",
              " {'category': 'GEOGRAPHY \"B\"',\n",
              "  'air_date': '2009-11-26',\n",
              "  'question': \"'The few people who live on this island partner of Antigua keep busy lobster fishing'\",\n",
              "  'value': '$1200',\n",
              "  'answer': 'Barbuda',\n",
              "  'round': 'Double Jeopardy!',\n",
              "  'show_number': '5799',\n",
              "  'predicted_question': [['question: Why do the few people who live on this island partner of Antigua keep busy lobster fishing?']]},\n",
              " {'category': 'FLAGS OF THE WORLD',\n",
              "  'air_date': '2000-07-19',\n",
              "  'question': \"'It's the kingdom whose flag is seen here (Union Jack)'\",\n",
              "  'value': '$100',\n",
              "  'answer': 'Great Britain/England',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '3673',\n",
              "  'predicted_question': [['question: Is it the kingdom whose flag is seen here (Union Jack)?']]},\n",
              " {'category': 'EUROPE',\n",
              "  'air_date': '2006-06-01',\n",
              "  'question': '\\'In a 1939 decree in Spain, he was proclaimed \"Supreme Chief, responsible only before God and history\"\\'',\n",
              "  'value': '$400',\n",
              "  'answer': 'Franco',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '5014',\n",
              "  'predicted_question': [['question: Why was EUROPE proclaimed \"Supreme Chief, responsible only before God and history\" in a 1939 decree in Spain?']]},\n",
              " {'category': \"ANCIENT VIP's\",\n",
              "  'air_date': '1987-11-10',\n",
              "  'question': \"'This Hebrew king taxed his people into rebellion, which may not have been too wise'\",\n",
              "  'value': '$200',\n",
              "  'answer': 'Solomon',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '732',\n",
              "  'predicted_question': [['question: What is the meaning of &quot;This Hebrew king taxed his people into rebellion, which may not have been too wise&quot']]},\n",
              " {'category': 'STATE SUPERLATIVES',\n",
              "  'air_date': '2007-05-30',\n",
              "  'question': \"'It pumps more than one million barrels of oil a day, more than any other state'\",\n",
              "  'value': '$600',\n",
              "  'answer': 'Texas',\n",
              "  'round': 'Jeopardy!',\n",
              "  'show_number': '5243',\n",
              "  'predicted_question': [['question: Why does it pump more than one million barrels of oil a day, more than any other state?']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(s):\n",
        "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "    import string, re\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "metadata": {
        "id": "ydNH6A8xnSR5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mqr_df = pd.read_csv('drive/MyDrive/t5-data/download/dev_mqr_with_category.tsv', sep='\\t')\n",
        "dev_count = len(dev_mqr_df)\n"
      ],
      "metadata": {
        "id": "tA_ydo67xbEf"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "c6tIVaXmx7rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "em_scores = []\n",
        "f1_scores = []\n",
        "import nltk\n",
        "from nltk.translate import bleu\n",
        "from nltk import bleu_score\n",
        "\n",
        "all_bleu = []\n",
        "\n",
        "for i in range(dev_count):\n",
        "  question, category = dev_mqr_df['ill formed'][i], dev_mqr_df['category'][i]\n",
        "  gt = [dev_mqr_df['well formed'][i].split()]\n",
        "  pred = hf_run_model(question, category)[0][0][9:].split()\n",
        "  \n",
        "\n",
        "  score = bleu_score.sentence_bleu(gt, pred)\n",
        "  all_bleu.append(score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jNhRYeDxuh_",
        "outputId": "96fa05b0-42c9-488e-a7fb-c457def29f36"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(all_bleu)/len(all_bleu) * 100) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVz-cYsH2K7_",
        "outputId": "6fd50819-653a-455b-e59e-83ed07239d8a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13.976663426215833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mqr_df = pd.read_csv('drive/MyDrive/t5-data/download/dev_mqr_with_category.tsv', sep='\\t')\n",
        "\n",
        "dev_mqr_df['make'] = dev_mqr_df['well formed'].str.split(' ').str[0]\n"
      ],
      "metadata": {
        "id": "zEGDfT023J5u"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qs = ['what', 'where', 'who', 'when', 'whose', 'which']\n",
        "dev_mqr_df = dev_mqr_df[dev_mqr_df['make'].str.contains('What|Where|Who|When|Whose|Which', regex=True)]"
      ],
      "metadata": {
        "id": "XB8NqbQRAdvE"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mqr_df = dev_mqr_df.drop('make', axis = 1)"
      ],
      "metadata": {
        "id": "47tXVPGwAgYN"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in dev_mqr_df.columns:\n",
        "    print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFujnLqGAh-Q",
        "outputId": "741d3217-a5cd-4b24-b334-24660d1669d5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ill formed\n",
            "well formed\n",
            "category\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollator, T5ForConditionalGeneration, T5TokenizerFast\n",
        "model = T5ForConditionalGeneration.from_pretrained('drive/MyDrive/t5-results/checkpoint-900')\n",
        "tokenizer = T5TokenizerFast.from_pretrained('t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elvfeoYGAw3X",
        "outputId": "e4011c98-e492-48a3-ccaf-673e504e401c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_bleu = []\n",
        "count = len(dev_mqr_df)\n",
        "\n",
        "for row in dev_mqr_df.iterrows():\n",
        "  # print(row)\n",
        "  question, category = row[1]['ill formed'], row[1]['category']\n",
        "  gt = [row[1]['well formed'].split()]\n",
        "  pred = hf_run_model(question, category)[0][0][9:].split()\n",
        "  # print(pred, gt)\n",
        "  \n",
        "\n",
        "  score = bleu_score.sentence_bleu(gt, pred)\n",
        "  # print(score)\n",
        "  all_bleu.append(score)\n",
        "\n",
        "print(sum(all_bleu)/len(all_bleu) * 100) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-OoWHpIAlj1",
        "outputId": "1974edb1-6a79-4dbb-b2ef-c7caf2987cf4"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.420572239751055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sam in sample_questions:\n",
        "  question, category = sam['question'], sam['category']\n",
        "  pred = hf_run_model(question, category)\n",
        "  sam['predicted_question'] = pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Z2y0oI5gAsco",
        "outputId": "671634c8-9fc8-49b6-a332-6b80c82a2c48"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-b7aa65f11aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_questions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_run_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0msam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_question'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-501537a20e12>\u001b[0m in \u001b[0;36mhf_run_model\u001b[0;34m(input_string, category, **generator_args)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0minput_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"generate question: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_string\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" </s>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerator_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<sep>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             )\n\u001b[1;32m   1607\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2800\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 )\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mquery_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_questions[0:10]"
      ],
      "metadata": {
        "id": "A0L6LaMiG2dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "79488b174ccc4d2980d16a679cca9315",
            "189739f4bff24ba3af39b945b114b6a0",
            "2bd79f3a51e14a9a9c7e7e493ae74c48",
            "d909e611f57b43e8a7f8fd88b7fa44c1",
            "c69f6c657c934109aa8a939342e2d22a",
            "22b04540d8114a99838ce87f8f620834",
            "25c4418fe18c4b4ea04d43466d13de70",
            "6d84525a84774a11a0a94de27de1d506",
            "f8054b77cecd468db046e63761fe69df",
            "56a120648d5947bdb1bd149311781f57",
            "a8415ffeb9504851a98e6daa300b9950",
            "572fdb37566e41a0b80ae4de3e82a18c",
            "98f4a1dcc69d4844a9f7f2c195ee83ba",
            "42c138e1fe1646789070a5ed6f1ca15f",
            "6824dae960964163b3e02e588b07ac87",
            "8f4656a7e5d04f5f9987dfd111e636c2",
            "9711a6d855f2483e9cc84272177fd4c8",
            "47c7e1c792e84864bf87ef8a6117991c",
            "a8726df5acdb4509ac43c2bbbc1c0fb0",
            "85053c24e2774c7bbad0397d629e1f00",
            "c2f88056197a49a5a4ffb36cb5e3dbcc",
            "f856012c1efd4258b0b5f7a1c845e1b9",
            "bbe596ff90c74faebb770a88e3c3d8d1",
            "6a182775d5b345bba335f28698023190",
            "a31366c7e11f41bf9a80651821712813",
            "cc83c3fb50ab435d89171e9aa8f1c040",
            "0d0722222d3a48dea4a347f13d390672",
            "0a491a4428e74a84bad6f4e812f08855",
            "9ddbc7e353864fa3a1977aa89597bdf2",
            "f2315d2f8e864f439282cea93f16e360",
            "0156f0225b4348f389b9960e3d081364",
            "f232e01b610b45aeabe7112e6d625996",
            "3e12ae1891fa4555b77c89546bc29ad6",
            "f083f92b327d480c89271fdef5d31bdf",
            "62f7389504a045e3862fd06946015d8a",
            "4c6885b6f2c046bcb18de2273a6a6d9c",
            "443bebc1c64447a3b38093dd7fad1aa0",
            "994cce208d2745c1900d6416c27e0b5f",
            "51245153225749819d1940924bfabfdb",
            "516720edae8c4de090e887e6b28b74da",
            "6410aae9620a4f9c9a2b2f1d5c735314",
            "0d327d681ad047acb51047187a01915e",
            "bce4bc9df9c2457b9ef5e15936aa05c7",
            "562f1a0ef54e44e4b1af390e408c1590",
            "fc55cc7810b94e268fbb76077ddca0d2",
            "37679f280fd845e593d2c5cdd3452309",
            "ba7b55dd6c514ee8bfd3bbe258e8a093",
            "6fd3c64c0a66404e9dadad1a6300c499",
            "2f72de0bdd4d49a7b5cc20e415494c14",
            "bd18c33670854db2a9fde9d1aeaf5859",
            "84d5ce3376e746c48638ef66f1cb7490",
            "85b97af3ca8c4273acd3551912a08395",
            "a4a1e2d0dece4feb9df2e02d4cecff81",
            "d13575c25000473ea28b3efe6b397da7",
            "efbba048f7fc4bbe8fb3cf061ae3dafc"
          ]
        },
        "id": "liG69gZbHXyZ",
        "outputId": "350bb6ee-98ca-4283-c999-f8353772d828"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79488b174ccc4d2980d16a679cca9315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572fdb37566e41a0b80ae4de3e82a18c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbe596ff90c74faebb770a88e3c3d8d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f083f92b327d480c89271fdef5d31bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc55cc7810b94e268fbb76077ddca0d2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_question(answer, context, max_length=64):\n",
        "  input_text = \"answer: %s  context: %s </s>\" % (answer, context)\n",
        "  features = tokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "  output = model.generate(input_ids=features['input_ids'], \n",
        "               attention_mask=features['attention_mask'],\n",
        "               max_length=max_length)\n",
        "\n",
        "  return tokenizer.decode(output[0])"
      ],
      "metadata": {
        "id": "oY2gaI4Dd3h8"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_mqr_df = pd.read_csv('drive/MyDrive/t5-data/download/dev_mqr_with_category.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "tD5dcmdyeEsO"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_bleu = []\n",
        "count = len(dev_mqr_df)\n",
        "\n",
        "for row in dev_mqr_df.iterrows():\n",
        "  # print(row)\n",
        "  question, category = row[1]['ill formed'], row[1]['category']\n",
        "  gt = row[1]['well formed']\n",
        "  pred = get_question(gt, question)\n",
        "\n",
        "  gt = [normalize_text(gt).split()]\n",
        "  pred = normalize_text(pred).split()[2:]\n",
        "\n",
        "\n",
        "  #print(pred, gt)\n",
        "  \n",
        "\n",
        "  score = bleu_score.sentence_bleu(gt, pred)\n",
        "  #print(score)\n",
        "  all_bleu.append(score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "cFT2LkdOeILm",
        "outputId": "9cd2aeca-2ddc-49b4-a71e-5c4ef26a9811"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-60a8dc2ed980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ill formed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'well formed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-180975e66aa2>\u001b[0m in \u001b[0;36mget_question\u001b[0;34m(answer, context, max_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   output = model.generate(input_ids=features['input_ids'], \n\u001b[0m\u001b[1;32m      6\u001b[0m                \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                max_length=max_length)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m             \u001b[0;31m# 10. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1519\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2286\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 )\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(all_bleu)/len(all_bleu) * 100) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2GWJbDOn1Nk",
        "outputId": "ff3c7187-05f9-4163-d153-ef1cc24f418f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.054466411193204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0epJp8TeXou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}